{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from inspect import signature\n",
    "from yaml import safe_load\n",
    "import pandas as pd \n",
    "import tqdm\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import faiss\n",
    "import gc\n",
    "from typing import Tuple\n",
    "import dotenv\n",
    "OUTPUT_DIR = Path(\"test_results\")\n",
    "today = pd.Timestamp.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XRIFGenerator:\n",
    "    def __init__(self, \n",
    "                 prompt_template: str,\n",
    "                 waypoints_csv: str,\n",
    "                 language_model_type = \"Ollama\",\n",
    "                 embed_model_type = \"Ollama\",\n",
    "                 language_model: str = \"deepseek-r1:1.5b\",\n",
    "                 embed_model: str = \"deepseek-r1:1.5b\",\n",
    "                 chat_kwargs: dict = {\"num_predict\": 500, \"temperature\": 0.2, \"top_p\": 0.2},\n",
    "                 fetch_all: bool = True):\n",
    "        self.waypoints_list = []\n",
    "        self.kwargs = chat_kwargs\n",
    "        self.prompt_template = prompt_template\n",
    "        self.waypoints_csv = waypoints_csv\n",
    "        self.x_coord = 0\n",
    "        self.y_coord = 0\n",
    "        print(f\"Loading model: {language_model}...\")\n",
    "        \n",
    "        if embed_model_type == \"Ollama\":\n",
    "            embed = OllamaEmbeddings(model = embed_model)\n",
    "        elif embed_model_type == \"HuggingFace\":\n",
    "            embed = HuggingFaceEmbeddings(model_name = embed_model)\n",
    "        else:\n",
    "            raise Exception(\"Invalid embed_model_type\")\n",
    "        \n",
    "        \n",
    "        if language_model_type == \"Ollama\":\n",
    "            self.llm = OllamaLLM(model=language_model, **self.filter_kwargs_for_OllamaLLM(self.kwargs))\n",
    "        elif language_model_type == \"google\":\n",
    "            if os.getenv(\"GOOGLE_API_KEY\"):\n",
    "                self.llm = GoogleGenerativeAI(model=language_model)\n",
    "            else:\n",
    "                raise Exception(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "        else:\n",
    "            raise Exception(\"Invalid language_model_type\")\n",
    "\n",
    "        self.output_parser = StrOutputParser()\n",
    "        waypoints = pd.read_csv(self.waypoints_csv)\n",
    "        waypoint_cols = ['Location', 'X co-ordinate', 'Y co-ordinate', 'Floor', 'Section', 'Keywords']\n",
    "        given_waypoints_cols = list(waypoints.columns)\n",
    "        if given_waypoints_cols != waypoint_cols:\n",
    "            raise Exception(\"Columns do not match, please provide a new dataset\")\n",
    "        \n",
    "        num_rows = len(waypoints)\n",
    "        print(f\"Processing {num_rows} waypoints...\")\n",
    "        with tqdm.tqdm(total=num_rows) as pbar:\n",
    "            for index, row in waypoints.iterrows():\n",
    "                keywords_string = ', '.join(row['Keywords'])\n",
    "                self.waypoints_list.append(Document(id = f\"Waypoint_{index}\", page_content=f\"A waypoint called {row['Location']} exists at X-Coordinate, {row['X co-ordinate']}, and Y-Coordinate, {row['Y co-ordinate']}, apart of Section, {row['Section']}. Words associated with the waypoint, {row['Location']} are {keywords_string}.\"))\n",
    "                pbar.update(1)\n",
    "        \n",
    "        index = faiss.IndexFlatL2(len(embed.embed_query(\"Hello World!\")))\n",
    "\n",
    "        self.vector_store = FAISS(\n",
    "            embedding_function=embed,\n",
    "            index=index,\n",
    "            docstore=InMemoryDocstore(),\n",
    "            index_to_docstore_id={}            \n",
    "        )\n",
    "        \n",
    "        print(\"Adding waypoints to vector store...\")\n",
    "        self.vector_store.add_documents(self.waypoints_list)\n",
    "        print(\"Creating retriever...\")\n",
    "        k = len(self.waypoints_list) if fetch_all else 5\n",
    "        \n",
    "        self.retriever = self.vector_store.as_retriever(\n",
    "            search_type = \"mmr\",\n",
    "            search_kwargs = {'k': k, 'fetch_k': len(self.waypoints_list)},\n",
    "        )\n",
    "\n",
    "        with open(self.prompt_template, 'r') as file:\n",
    "            prompt_dict = safe_load(file)\n",
    "            self.prompt = prompt_dict['prompt']\n",
    "            self.prompt_name = prompt_dict['prompt_name']\n",
    "        \n",
    "        print(\"Creating prompt template...\")\n",
    "        self.prompt_template = PromptTemplate(template=self.prompt, input_variables=[\"documents\", \"query\", \"starting_location\"])\n",
    "\n",
    "        print(\"Creating RAG chain...\")\n",
    "        self.rag_chain = self.prompt_template | self.llm | self.output_parser\n",
    "        \n",
    "    def filter_kwargs_for_OllamaLLM(self, kwargs: dict) -> dict:\n",
    "        chatollama_params = signature(OllamaLLM.__init__).parameters\n",
    "        return {k: v for k, v in kwargs.items() if k in chatollama_params}\n",
    "    \n",
    "    def generate_xrif_with_deepseek_model(self, query: str):\n",
    "        xrif_response = None\n",
    "        documents = self.retriever.invoke(query)\n",
    "        doc_texts = \"\\\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "        rendered_prompt = self.prompt_template.format({\"documents\": doc_texts, \"query\": query, \"starting_location\": f\"X-Coordinate: {self.x_coord}, Y-Coordinate: {self.y_coord}\"})\n",
    "\n",
    "        llm_response = self.rag_chain.invoke({\"documents\": doc_texts, \"query\": query, \"starting_location\": f\"X-Coordinate: {self.x_coord}, Y-Coordinate: {self.y_coord}\"})\n",
    "\n",
    "        xrif_response = re.sub(r\"<think>.*?</think>\", \"\", llm_response, flags=re.DOTALL)\n",
    "\n",
    "        xrif_response = re.sub(r\"\\n\", \"\", xrif_response)\n",
    "\n",
    "        xrif_response = re.sub(r\"\\\\n\", \"\", xrif_response)\n",
    "\n",
    "        start = xrif_response.find('{')\n",
    "        end = xrif_response.rfind('}')\n",
    "\n",
    "        if start != -1 and end != -1:\n",
    "            xrif_response = xrif_response[start:end+1]\n",
    "            try:\n",
    "                xrif_response = json.loads(xrif_response)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"Error parsing JSON response\")\n",
    "\n",
    "        \n",
    "        return llm_response, xrif_response, doc_texts, rendered_prompt\n",
    "    \n",
    "    def batch_test_run(self, df: pd.DataFrame, output_folder: Path):\n",
    "        num_rows = len(df)\n",
    "        print(f\"Processing {num_rows} test prompts...\")\n",
    "        with tqdm.tqdm(total=num_rows) as pbar:\n",
    "            for index, row in df.iterrows():\n",
    "                now = pd.Timestamp.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "                dump_json = {}\n",
    "                error_message = 'No Error'\n",
    "                note = ''\n",
    "                query = row['Prompt']\n",
    "                self.x_coord = row['Starting X']\n",
    "                self.y_coord = row['Starting Y']\n",
    "                expected_response = row['Expected Response']\n",
    "                llm_response, xrif_response = self.generate_xrif_with_deepseek_model(query)\n",
    "\n",
    "                dump_json['Data Set'] = row['Data Set']\n",
    "                dump_json['Experiment ID'] = row['Experiment ID']\n",
    "                dump_json['Prompt ID'] = row['Prompt ID']\n",
    "                dump_json['Prompt'] = query\n",
    "                dump_json['Full LLM Response'] = str(llm_response)\n",
    "                dump_json['XRIF Generated'] = xrif_response if isinstance(xrif_response, dict) else str(xrif_response)\n",
    "                dump_json['Starting X'] = self.x_coord\n",
    "                dump_json['Starting Y'] = self.y_coord\n",
    "                dump_json['Expected Response'] = expected_response\n",
    "                dump_json['Expected Response Type'] = row['Expected Response Type']\n",
    "                expected_response = list(expected_response)\n",
    "                if xrif_response and type(xrif_response) == dict:\n",
    "                    if 'actions' in xrif_response.keys():\n",
    "                        actions = xrif_response['actions']\n",
    "                        if len(expected_response) == len(actions):\n",
    "                            if row['Expected Response Type'] == 'Nav':\n",
    "                                list_of_locations = [action['input']['name'] for action in actions if (action['action'] == 'navigate') and ('input' in action) and ('name' in action['input'])]\n",
    "                                set_of_locations = set(list_of_locations)\n",
    "                                set_of_expected_locations = set(expected_response)\n",
    "                                if set_of_locations == set_of_expected_locations:\n",
    "                                    note = \"All locations are present in the response\"\n",
    "                                    dump_json['Notes'] = note\n",
    "                            for i in range(len(xrif_response['actions'])):\n",
    "                                if actions[i]['action'] == 'navigate' :\n",
    "                                    if type(expected_response[i]) == 'str':\n",
    "                                        if 'input' in actions[i]:\n",
    "                                            if 'name' in actions[i]['input'].keys():\n",
    "                                                if actions[i]['input']['name'] == expected_response[i] or (type(expected_response[i]) == 'list' and actions[i]['input']['name'] in expected_response[i]):\n",
    "                                                    continue\n",
    "                                                else:\n",
    "                                                    error_message = f\"Expected location name: {actions[i]['name']} does not match with the provided location name: {expected_response[i]}\"\n",
    "                                                    dump_json['Error Message'] = error_message\n",
    "                                                    break\n",
    "                                            else:\n",
    "                                                error_message = f\"Response Error Missing field: 'name' in action object {i}\"\n",
    "                                                dump_json['Error Message'] = error_message\n",
    "                                                break\n",
    "                                        else:\n",
    "                                            error_message = f\"Response Error Missing field: 'input' in action object {i}\"\n",
    "                                            dump_json['Error Message'] = error_message\n",
    "                                            break\n",
    "                                    else:\n",
    "                                        error_message = f\"Expected Response Error: Expected Response Type is not 'Nav' for action object {i}\"\n",
    "                                        dump_json['Error Message'] = error_message\n",
    "                                        break\n",
    "                                elif actions[i]['action'] == 'wait':\n",
    "                                    if type(expected_response[i]) == 'tuple':\n",
    "                                        if 'input' in actions[i]:\n",
    "                                                if actions[i]['action'] != expected_response[i][0]:\n",
    "                                                    error_message = f\"Expected action at action object {i} : {expected_response[i][0]}  does not match with the provided action: {actions[i]['action']}\"\n",
    "                                                    dump_json['Error Message'] = error_message\n",
    "                                                    break\n",
    "                                                else:\n",
    "                                                    if (int(actions[i]['input']))/60 == expected_response[i][1]:\n",
    "                                                        error_message = f\"Expected wait time: {actions[i]['input']} does not match with the provided wait time: {expected_response[i][1]}\"\n",
    "                                                        dump_json['Error Message'] = error_message\n",
    "                                                        break\n",
    "                                        else:\n",
    "                                            error_message = f\"Response Error Missing field: 'input' in action object {i}\"\n",
    "                                            dump_json['Error Message'] = error_message\n",
    "                                            break\n",
    "                                    else:\n",
    "                                        error_message = f\"Expected Response Error: Expected Response Type is not 'wait' for action object {i}\"\n",
    "                                        dump_json['Error Message'] = error_message\n",
    "                                        break\n",
    "                                elif actions[i]['action'] == 'speak':\n",
    "                                    if type(expected_response[i]) == 'tuple':\n",
    "                                        if ('action' in actions[i]) and ('input' in actions[i]):\n",
    "                                            if actions[i]['action'] == expected_response[i][0] and (actions[i]['input'] == expected_response[i][1] or (type(expected_response[i]) == 'list' and actions[i]['input'] in expected_response[i])):\n",
    "                                                continue\n",
    "                                            else:\n",
    "                                                error_message = f\"Expected speak message: {expected_response[i]} does not match with the generated speak message: {actions[i]['input']} or Expected action: {expected_response[i][0]} does not match with the generated action: {actions[i]['action']}\"\n",
    "                                                dump_json['Error Message'] = error_message\n",
    "                                                break\n",
    "                                        else:\n",
    "                                            error_message = f\"Response Error Missing field: 'input' or 'action' in action object {i}\"\n",
    "                                            dump_json['Error Message'] = error_message\n",
    "                                            break\n",
    "                                    else:\n",
    "                                        error_message = f\"Expected Response Error: Expected Response Type is not correct for action object {i}\"\n",
    "                                        dump_json['Error Message'] = error_message\n",
    "                                        break\n",
    "                else:\n",
    "                    error_message = \"XRIF response is Invalid\"\n",
    "                    dump_json['Error Message'] = error_message\n",
    "                \n",
    "                if not os.path.exists(OUTPUT_DIR / output_folder):\n",
    "                    os.makedirs(OUTPUT_DIR / output_folder)\n",
    "\n",
    "                with open(OUTPUT_DIR / output_folder / f\"Prompt_{row['Prompt ID']}_{now}.json\", 'w') as file:\n",
    "                    json.dump(dump_json, file, indent=4)\n",
    "                pbar.update(1)\n",
    "\n",
    "        return OUTPUT_DIR / output_folder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_dataset(dataset: pd.DataFrame):\n",
    "    dataset['Expected Response'] = dataset['Expected Response'].to_list()\n",
    "    dataset.dropna(subset=['Prompt', 'Expected Response'], inplace=True)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_experiment_from_config(config_file: Path) -> Tuple[XRIFGenerator, pd.DataFrame, Path]:\n",
    "    with open(config_file, 'r') as file:\n",
    "        config_dict = safe_load(file)\n",
    "        test_dataset_path = config_dict['test_dataset']\n",
    "\n",
    "        test_dataset = pd.read_csv(test_dataset_path)\n",
    "        output_folder = config_dict['output_folder']\n",
    "\n",
    "        del config_dict['output_folder']\n",
    "        del config_dict['test_dataset']\n",
    "\n",
    "        test_dataset = process_test_dataset(test_dataset)\n",
    "        \n",
    "        return XRIFGenerator(**config_dict), test_dataset, output_folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
