{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting Experiments\n",
    "In this notebook, we are experimenting with various few-shot and chain-of-thought prompts that can translate queries such as \"Can you get me a coffee\" into a sequence of actions and responses that a robot would perform.\n",
    "\n",
    "Research Ideas:\n",
    "- Waypoint-based navigation in ambiguous environments such as UWaterloo campus or in a parts storage warehouse\n",
    "- Spatial Knowledge (coordinates in context)\n",
    "- Update waypoint info + context automatically\n",
    "    - \"Remember that Zach's office is room 2441\"\n",
    "    - \"The best place to get chips is the vending machine\"\n",
    "- What happens when you have a lot of waypoints in the context\n",
    "- What to do when two waypoints match a simple description\n",
    "- Ask to clarify if there is unclear information\n",
    "- Modes -> teleop, nav, conversation-only\n",
    "- Dynamic Waypoint Generation\n",
    "    - During manual teleop -> \"Remember this location you just passed by, this is called Room 2106\"\n",
    "    - Use camera to pick up potential new waypoints/context -> Robot says \"I passed by a fire extinguisher, should I make a new waypoint?\"\n",
    "- Image Embeddings for waypoints \n",
    "    - Remember what certain places look like / what points/objects of interest are near that waypoint\n",
    "- Robot Knowledge Graph (use graph nav notebook)\n",
    "    - Remember waypoint locations\n",
    "    - Remember people you've met -> \"Hey I'm Zach, go to my office\"\n",
    "- Looping tasks -> \"Do this 5 times\"\n",
    "- Scheduling tasks -> \"At 2pm, take a picture of the north entrance\"\n",
    "    - eventually -> task duration estimates\n",
    "    - Check at regular intervals if you have a task you're supposed to do right now\n",
    "- Test different floors -> ex: warehouse with different sections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 1)) (2.2.3)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 2)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 3)) (3.10.0)\n",
      "Requirement already satisfied: haystack-ai in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 4)) (2.10.3)\n",
      "Requirement already satisfied: seaborn in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 5)) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 6)) (1.6.1)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 7)) (4.49.0)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 8)) (2.6.0)\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 9)) (0.21.0)\n",
      "Requirement already satisfied: cohere in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 10)) (5.13.12)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 11)) (1.64.0)\n",
      "Requirement already satisfied: wandb in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 12)) (0.19.7)\n",
      "Requirement already satisfied: dotenv in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 13)) (0.9.9)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (from -r requirements.in (line 14)) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas->-r requirements.in (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas->-r requirements.in (line 2)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas->-r requirements.in (line 2)) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib->-r requirements.in (line 3)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.11/site-packages (from matplotlib->-r requirements.in (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.11/site-packages (from matplotlib->-r requirements.in (line 3)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib->-r requirements.in (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from matplotlib->-r requirements.in (line 3)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.11/site-packages (from matplotlib->-r requirements.in (line 3)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib->-r requirements.in (line 3)) (3.2.1)\n",
      "Requirement already satisfied: haystack-experimental in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (3.1.5)\n",
      "Requirement already satisfied: jsonschema in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (4.23.0)\n",
      "Requirement already satisfied: lazy-imports in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (0.4.0)\n",
      "Requirement already satisfied: more-itertools in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (10.6.0)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (3.4.2)\n",
      "Requirement already satisfied: openapi-llm>=0.4.1 in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (0.4.1)\n",
      "Requirement already satisfied: posthog<3.12.0 in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (3.11.0)\n",
      "Requirement already satisfied: pydantic in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (6.0.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.11/site-packages (from haystack-ai->-r requirements.in (line 4)) (4.12.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.11/site-packages (from scikit-learn->-r requirements.in (line 6)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.11/site-packages (from scikit-learn->-r requirements.in (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.11/site-packages (from scikit-learn->-r requirements.in (line 6)) (3.5.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from transformers->-r requirements.in (line 7)) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./venv/lib/python3.11/site-packages (from transformers->-r requirements.in (line 7)) (0.29.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.11/site-packages (from transformers->-r requirements.in (line 7)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.11/site-packages (from transformers->-r requirements.in (line 7)) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.11/site-packages (from transformers->-r requirements.in (line 7)) (0.5.2)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.11/site-packages (from torch->-r requirements.in (line 8)) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./venv/lib/python3.11/site-packages (from torch->-r requirements.in (line 8)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.11/site-packages (from sympy==1.13.1->torch->-r requirements.in (line 8)) (1.3.0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in ./venv/lib/python3.11/site-packages (from cohere->-r requirements.in (line 10)) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.21.2 in ./venv/lib/python3.11/site-packages (from cohere->-r requirements.in (line 10)) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in ./venv/lib/python3.11/site-packages (from cohere->-r requirements.in (line 10)) (0.4.0)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in ./venv/lib/python3.11/site-packages (from cohere->-r requirements.in (line 10)) (2.27.2)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in ./venv/lib/python3.11/site-packages (from cohere->-r requirements.in (line 10)) (2.32.0.20241016)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.11/site-packages (from openai->-r requirements.in (line 11)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.11/site-packages (from openai->-r requirements.in (line 11)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.11/site-packages (from openai->-r requirements.in (line 11)) (0.8.2)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai->-r requirements.in (line 11)) (1.3.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in ./venv/lib/python3.11/site-packages (from wandb->-r requirements.in (line 12)) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./venv/lib/python3.11/site-packages (from wandb->-r requirements.in (line 12)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./venv/lib/python3.11/site-packages (from wandb->-r requirements.in (line 12)) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in ./venv/lib/python3.11/site-packages (from wandb->-r requirements.in (line 12)) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in ./venv/lib/python3.11/site-packages (from wandb->-r requirements.in (line 12)) (5.29.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./venv/lib/python3.11/site-packages (from wandb->-r requirements.in (line 12)) (7.0.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./venv/lib/python3.11/site-packages (from wandb->-r requirements.in (line 12)) (2.22.0)\n",
      "Requirement already satisfied: setproctitle in ./venv/lib/python3.11/site-packages (from wandb->-r requirements.in (line 12)) (1.3.4)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.11/site-packages (from wandb->-r requirements.in (line 12)) (65.5.0)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.11/site-packages (from dotenv->-r requirements.in (line 13)) (1.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.in (line 11)) (3.10)\n",
      "Requirement already satisfied: six>=1.4.0 in ./venv/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.in (line 12)) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.in (line 12)) (4.0.12)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx>=0.21.2->cohere->-r requirements.in (line 10)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.21.2->cohere->-r requirements.in (line 10)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere->-r requirements.in (line 10)) (0.14.0)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.11/site-packages (from openapi-llm>=0.4.1->haystack-ai->-r requirements.in (line 4)) (3.11.12)\n",
      "Requirement already satisfied: jsonref in ./venv/lib/python3.11/site-packages (from openapi-llm>=0.4.1->haystack-ai->-r requirements.in (line 4)) (1.1.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./venv/lib/python3.11/site-packages (from posthog<3.12.0->haystack-ai->-r requirements.in (line 4)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./venv/lib/python3.11/site-packages (from posthog<3.12.0->haystack-ai->-r requirements.in (line 4)) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic->haystack-ai->-r requirements.in (line 4)) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests->haystack-ai->-r requirements.in (line 4)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests->haystack-ai->-r requirements.in (line 4)) (2.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->haystack-ai->-r requirements.in (line 4)) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.11/site-packages (from jsonschema->haystack-ai->-r requirements.in (line 4)) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.11/site-packages (from jsonschema->haystack-ai->-r requirements.in (line 4)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.11/site-packages (from jsonschema->haystack-ai->-r requirements.in (line 4)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.11/site-packages (from jsonschema->haystack-ai->-r requirements.in (line 4)) (0.23.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.in (line 12)) (5.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp->openapi-llm>=0.4.1->haystack-ai->-r requirements.in (line 4)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.11/site-packages (from aiohttp->openapi-llm>=0.4.1->haystack-ai->-r requirements.in (line 4)) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.11/site-packages (from aiohttp->openapi-llm>=0.4.1->haystack-ai->-r requirements.in (line 4)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.11/site-packages (from aiohttp->openapi-llm>=0.4.1->haystack-ai->-r requirements.in (line 4)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.11/site-packages (from aiohttp->openapi-llm>=0.4.1->haystack-ai->-r requirements.in (line 4)) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.11/site-packages (from aiohttp->openapi-llm>=0.4.1->haystack-ai->-r requirements.in (line 4)) (1.18.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krajesh/cookbook/experiments/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import yaml\n",
    "from typing import Dict, Any\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import cohere\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from openai import OpenAI\n",
    "from haystack import Pipeline, Document\n",
    "from haystack.utils import Secret\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import HuggingFaceLocalGenerator\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "if COHERE_API_KEY is None:\n",
    "    raise ValueError(\"COHERE_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "We'll use Cohere as a baseline alongside DeepSeek-R1 7B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_client = cohere.ClientV2(api_key=COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_cohere(prompt, model_name = \"command-r-plus-08-2024\"):\n",
    "    global cohere_client\n",
    "    response = cohere_client.chat(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\" : \"user\",\n",
    "                \"content\" : prompt\n",
    "            }\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return response.message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XRIF V1\n",
    "The goal of XRIF V1 is to be easily serializable (using JSON for now), making it easy to generate with simple in-context learning and chain of thought prompts. Beyond prompt engineering, fine-tuning experiments can enable smaller models to better produce more accurate XRIF instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "e7_xrif_with_waypoint_keywords = \"\"\"\n",
    "You control a robot that can navigate through a building based on a json instruction format,\n",
    "you understand several waypoints that have been given to you before (you can use RAG to retrieve\n",
    "what room numbers or waypoints correspond to which people or semantics).\n",
    "\n",
    "Here are all the waypoints you have access to:\n",
    "- E7 1st floor Elevators, floor: 1, keywords = [\"elevator\"]\n",
    "- E7 North Entrance, floor: 1, keywords = [\"entrance\"]\n",
    "- E7 East Entrance, floor: 1, keywords = [\"entrance\"]\n",
    "- E7 South Entrance, floor: 1, keywords = [\"entrance\"]\n",
    "- E7 Coffee and Donuts, floor: 1, keywords = [\"food and drink\", \"coffee\"]\n",
    "- Outreach Classroom, floor: 1, keywords = [\"classroom\"]\n",
    "- RoboHub Entrance, floor: 1, keywords = [\"workshop\", \"robots\", \"Brandon\"]\n",
    "- Vending Machine, floor: 1, keywords = [\"food and drink\"]\n",
    "- Room 2106, floor: 2, keywords = [\"office\", \"zach\", \"WEEF\"]\n",
    "\n",
    "Extra information:\n",
    "- Room 2106 is Zach's office\n",
    "- Coffee and Donuts is referred to as CnD\n",
    "\n",
    "Prompt: Can you pick something up from Zach's office and drop it off at the RoboHub?\n",
    "\n",
    "Answer:\n",
    "{\n",
    "    \"goals\": [\n",
    "        {\n",
    "            \"name\": \"Room 2106\",\n",
    "            \"keywords\": [\"office\", \"zach\", \"WEEF\"],\n",
    "            \"floor\": 1\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"RoboHub Entrance\",\n",
    "            \"keywords\": [\"workshop\", \"robots\", \"Brandon\"]\n",
    "            \"floor\": 1\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "Prompt:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    \"Send a Coffee to Zach's Office\",\n",
    "    \"Get me an energy drink, I'm in the RoboHub\",\n",
    "    \"go to the south entrance then the north entrance\",\n",
    "]\n",
    "\n",
    "def run_experiment(prefix, list_of_inputs):\n",
    "    for input in list_of_inputs:\n",
    "        print(f\"Input: {input}\")\n",
    "        print(prompt_cohere(f\"{prefix}{input}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XRIF V2\n",
    "V2 introduces action calling, which allows XRIF to go beyond just waypoint navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "XRIF_MODES = [\"learning\", \"navigating\", \"conversation\", \"teleop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "waypoint_list_v1 = [\n",
    "{\n",
    "    \"name\": \"E7 1st floor Elevators\",\n",
    "    \"x\": 50,\n",
    "    \"y\": 50,\n",
    "    \"floor\": 1,\n",
    "    \"keywords\": [\"elevator\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"E7 North Entrance\",\n",
    "    \"x\": 50,\n",
    "    \"y\": 0,\n",
    "    \"floor\": 1,\n",
    "    \"keywords\": [\"entrance\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"E7 East Entrance\",\n",
    "    \"x\": 0,\n",
    "    \"y\": 50,\n",
    "    \"floor\": 1,\n",
    "    \"keywords\": [\"entrance\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"E7 South Entrance\",\n",
    "    \"x\": 50,\n",
    "    \"y\": 100,\n",
    "    \"floor\": 1,\n",
    "    \"keywords\": [\"entrance\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"E7 Coffee and Donuts\",\n",
    "    \"x\": 75,\n",
    "    \"y\": 75,\n",
    "    \"floor\": 1,\n",
    "    \"keywords\": [\"food and drink\", \"coffee\", \"breakfast\", \"snacks\"],\n",
    "    \"aliases\": [\"CnD\", \"C and D\"]\n",
    "},\n",
    "{\n",
    "    \"name\": \"Room 1427 - Ideas Clinic\",\n",
    "    \"x\": 25,\n",
    "    \"y\": 75,\n",
    "    \"floor\": 1,\n",
    "    \"keywords\": [\"classroom\", \"workshop\", \"lab\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"Outreach Classroom\",\n",
    "    \"x\": 25,\n",
    "    \"y\": 25,\n",
    "    \"floor\": 1,\n",
    "    \"keywords\": [\"classroom\", \"lecture hall\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"RoboHub Entrance\",\n",
    "    \"x\": 25,\n",
    "    \"y\": 50,\n",
    "    \"floor\": 1,\n",
    "    \"keywords\": [\"robots\", \"workshop\", \"lab\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"Vending Machine\",\n",
    "    \"x\": 75,\n",
    "    \"y\": 50,\n",
    "    \"floor\": 1,\n",
    "    \"keywords\": [\"food and drink\", \"snacks\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"Room 2241\",\n",
    "    \"x\": 100,\n",
    "    \"y\": 100,\n",
    "    \"floor\": 2,\n",
    "    \"keywords\": [\"office\", \"Zach\"],\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_list_v1 = [\n",
    "{\n",
    "    \"name\": \"navigate\",\n",
    "    \"input\": [\"waypoint\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"wait\",\n",
    "    \"input\": [\"seconds\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"speak\",\n",
    "    \"input\": [\"output\"],\n",
    "},\n",
    "{\n",
    "    \"name\": \"add_waypoint\",\n",
    "    \"input\": [\"waypoint\"],\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrif_with_actions_1 = \"\"\"\n",
    "You control a robot that can navigate through a building based on a json instruction format, you understand several waypoints that have been given to you before (you can use RAG to retrieve what room numbers or waypoints correspond to which people or semantics).\n",
    "\n",
    "Here are all the waypoints you have access to:\n",
    "{{ waypoints_list }}\n",
    "\n",
    "Here are all the functions you have access to:\n",
    "{{ actions_list }}\n",
    "\n",
    "Example Prompt: Can you pick something up from Zach's office and drop it off at the RoboHub?\n",
    "\n",
    "Example Answer:\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"action\": \"navigate\",\n",
    "            \"input\": {\n",
    "                \"name\": \"Room 2241\",\n",
    "                \"x\": 100,\n",
    "                \"y\": 100,\n",
    "                \"floor\": 2,\n",
    "                \"keywords\": [\"office\", \"Zach\"],\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"action\": \"navigate\",\n",
    "            \"input\": {\n",
    "                \"name\": \"RoboHub Entrance\",\n",
    "                \"x\": 25,\n",
    "                \"y\": 50,\n",
    "                \"floor\": 1,\n",
    "                \"keywords\": [\"robots\", \"workshop\", \"lab\"],\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "Example Prompt: Can you ask Zach for the keys and drop it off at the ideas clinic? Wait for 10 seconds when you meet Zach so he can give you the keys.\n",
    "\n",
    "Example Answer:\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"action\": \"navigate\",\n",
    "            \"input\": {\n",
    "                \"name\": \"Room 2241\",\n",
    "                \"x\": 100,\n",
    "                \"y\": 100,\n",
    "                \"floor\": 2,\n",
    "                \"keywords\": [\"office\", \"Zach\"],\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"action\": \"speak\",\n",
    "            \"input\": \"Hey Zach, Can you hand me the keys?\",\n",
    "        },\n",
    "        {\n",
    "            \"action\": \"wait\",\n",
    "            \"input\": 10,\n",
    "        },\n",
    "        {\n",
    "            \"action\": \"navigate\",\n",
    "            \"input\": {\n",
    "                \"name\": \"Room 1427 - Ideas Clinic\",\n",
    "                \"x\": 25,\n",
    "                \"y\": 75,\n",
    "                \"floor\": 1,\n",
    "                \"keywords\": [\"classroom\", \"workshop\", \"lab\"],\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "Prompt: {{ query }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e7_xrif_with_actions_2 = \"\"\"\n",
    "# Role \n",
    "You control a robot that can navigate through a building based on a json instruction format, you understand several waypoints that have been provided in your context.\n",
    "\n",
    "# Context\n",
    "Here are all the waypoints you have access to:\n",
    "{{ waypoints_list }}\n",
    "\n",
    "Here are all the Functions you have access to:\n",
    "{{ actions_list }}\n",
    "\n",
    "# Examples\n",
    "Example Prompt: Can you pick something up from Zach's office and drop it off at the RoboHub?\n",
    "\n",
    "Example Answer:\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"action\": \"navigate\",\n",
    "            \"input\": {\n",
    "                \"name\": \"Room 2241\",\n",
    "                \"x\": 100,\n",
    "                \"y\": 100,\n",
    "                \"floor\": 2,\n",
    "                \"keywords\": [\"office\", \"Zach\"],\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"action\": \"navigate\",\n",
    "            \"input\": {\n",
    "                \"name\": \"RoboHub Entrance\",\n",
    "                \"x\": 25,\n",
    "                \"y\": 50,\n",
    "                \"floor\": 1,\n",
    "                \"keywords\": [\"robots\", \"workshop\", \"lab\"],\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "Example Prompt: Can you ask Zach for the keys and drop it off at the ideas clinic? Wait for 10 seconds when you meet Zach so he can give you the keys.\n",
    "\n",
    "Example Answer:\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"action\": \"navigate\",\n",
    "            \"input\": {\n",
    "                \"name\": \"Room 2241\",\n",
    "                \"x\": 100,\n",
    "                \"y\": 100,\n",
    "                \"floor\": 2,\n",
    "                \"keywords\": [\"office\", \"Zach\"],\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"action\": \"speak\",\n",
    "            \"input\": \"Hey Zach, Can you hand me the keys?\",\n",
    "        },\n",
    "        {\n",
    "            \"action\": \"wait\",\n",
    "            \"input\": 10,\n",
    "        },\n",
    "        {\n",
    "            \"action\": \"navigate\",\n",
    "            \"input\": {\n",
    "                \"name\": \"Room 1427 - Ideas Clinic\",\n",
    "                \"x\": 25,\n",
    "                \"y\": 75,\n",
    "                \"floor\": 1,\n",
    "                \"keywords\": [\"classroom\", \"workshop\", \"lab\"],\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "Prompt: {{ query }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMGenerator():\n",
    "  def __init__(self, \n",
    "               model_name: str, \n",
    "               task: str, \n",
    "               waypoints_csv: str,\n",
    "               promp_metadata_file : str, \n",
    "               generation_kwargs = {\"max_new_tokens\": 5000, \"temperature\": 0.9}):\n",
    "    self.model_name = model_name\n",
    "    self.task = task\n",
    "    self.generation_kwargs = generation_kwargs\n",
    "    self.waypoints = waypoints_csv\n",
    "    self.waypoints_list = []\n",
    "    self.document_store = InMemoryDocumentStore()\n",
    "    self.prompt_metadata = promp_metadata_file\n",
    "    self.llm = HuggingFaceLocalGenerator(model=self.model_name, task=self.task, generation_kwargs = self.generation_kwargs)\n",
    "\n",
    "    with open(self.prompt_metadata, 'r') as file:\n",
    "      prompt_dict = yaml.safe_load(file)\n",
    "      self.prompt = prompt_dict['prompt']\n",
    "      self.prompt_name = prompt_dict['prompt_name']\n",
    "\n",
    "    \n",
    "    self.retriever = InMemoryBM25Retriever(document_store=self.document_store)\n",
    "    self.prompt_builder = PromptBuilder(template=self.prompt)\n",
    "    waypoints_csv = pd.read_csv(self.waypoints)\n",
    "    waypoint_cols = ['Location', 'X co-ordinate', 'Y co-ordinate', 'Floor', 'Section', 'Keywords']\n",
    "    given_waypoints_cols = list(waypoints_csv.columns)\n",
    "    if given_waypoints_cols != waypoint_cols:\n",
    "      raise Exception(\"Columns do not match, please provide a new dataset\")\n",
    "    \n",
    "    \n",
    "    for index, row in waypoints_csv.iterrows():\n",
    "      self.waypoints_list.append(Document(content=f\"Location Name: {row['Location']} X-Coordinate: {row['X co-ordinate']} Y-Coordinate: {row['Y co-ordinate']} Section: {row['Section']} Keywords: {row['Keywords']}\"))\n",
    "\n",
    "    self.document_store.write_documents(self.waypoints_list)\n",
    "    self.pipeline = Pipeline()\n",
    "\n",
    "    self.pipeline.add_component(\"retriever\", self.retriever)\n",
    "    self.pipeline.add_component(\"prompt_builder\", self.prompt_builder)\n",
    "    self.pipeline.add_component(\"generator\", self.llm)\n",
    "    self.pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "    self.pipeline.connect(\"prompt_builder\", \"generator\")\n",
    "  \n",
    "  def generate(self, query: str):\n",
    "    res = self.pipeline.run({\n",
    "      \"prompt_builder\": {\n",
    "        \"query\": query\n",
    "      },\n",
    "      \"retriever\" : {\n",
    "        \"query\": query\n",
    "      }\n",
    "\n",
    "    })\n",
    "\n",
    "    return res['generator']['replies'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = LLMGenerator(model_name=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", task=\"text-generation\", waypoints_csv=\"datasets/uw_e7_floor1.csv\", promp_metadata_file=\"prompts/few_shot_xrif.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Device set to use mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, so I\\'m trying to help the user generate a JSON response for their path planning agent. The prompt they provided is \"Can you pick something up from Zach\\'s office and drop it off at the RoboHub?\" and there\\'s a list of waypoints provided. \\n\\nFirst, I need to understand what each waypoint represents. From the example given, it looks like each location has specific coordinates, keywords, and sections. So, each location\\'s information is tied to these key points.\\n\\nThe user\\'s prompt asks to pick something from Zach\\'s office. So, I should check if Zach\\'s office is listed as a location. Looking at the provided waypoints, the closest is \"C&D - Main Entrance\". But I notice that some locations are more about their features and keywords than just locations. For instance, \"Shower A\" has coordinates but no location name. So, I might need to treat that as a separate entity.\\n\\nSince the user wants to pick something up, I should include the \"C&D - Main Entrance\" as the location to pick from. Then, the target is \"RoboHub\". So, I\\'ll structure the JSON with a \"goals\" array containing two objects: one for picking up from Zach\\'s office and another for dropping it off at RoboHub.\\n\\nI should make sure the keys are correct and match the example provided. That way, the system can interpret the data properly and apply it to the user\\'s query. If I were to write this, I\\'d have to map each location to its respective coordinates and keywords to ensure the system can retrieve the correct information accurately.\\n</think>\\n\\n```json\\n{\\n    \"goals\": [\\n        {\\n            \"name\": \"C&D - Main Entrance\",\\n            \"floor\": 1,\\n            \"keywords\": {\\n                \"X-Coordinate\": 1965,\\n                \"Y-Coordinate\": 1132,\\n                \"Section\": \"C&D\",\\n                \"Keywords\": [\"Coffee and Donuts, Cafe, Coffee Shop, Store, Snacks, Drinks, 1416\"]\\n            }\\n        },\\n        {\\n            \"name\": \"RoboHub\",\\n            \"floor\": 1,\\n            \"keywords\": {\\n                \"X-Coordinate\": 1339,\\n                \"Y-Coordinate\": 906,\\n                \"Section\": \"RoboHub\",\\n                \"Keywords\": [\"Robotics, 1339, Robot, Drone\"]\\n            }\\n        }\\n    ]\\n}\\n```'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepseek.generate(\"Can you pick something up from Zach's office and drop it off at the RoboHub?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, so I'm trying to help the user generate a JSON response for their path planning agent. The prompt they provided is \"Can you pick something up from Zach's office and drop it off at the RoboHub?\" and there's a list of waypoints provided. \n",
      "\n",
      "First, I need to understand what each waypoint represents. From the example given, it looks like each location has specific coordinates, keywords, and sections. So, each location's information is tied to these key points.\n",
      "\n",
      "The user's prompt asks to pick something from Zach's office. So, I should check if Zach's office is listed as a location. Looking at the provided waypoints, the closest is \"C&D - Main Entrance\". But I notice that some locations are more about their features and keywords than just locations. For instance, \"Shower A\" has coordinates but no location name. So, I might need to treat that as a separate entity.\n",
      "\n",
      "Since the user wants to pick something up, I should include the \"C&D - Main Entrance\" as the location to pick from. Then, the target is \"RoboHub\". So, I'll structure the JSON with a \"goals\" array containing two objects: one for picking up from Zach's office and another for dropping it off at RoboHub.\n",
      "\n",
      "I should make sure the keys are correct and match the example provided. That way, the system can interpret the data properly and apply it to the user's query. If I were to write this, I'd have to map each location to its respective coordinates and keywords to ensure the system can retrieve the correct information accurately.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"goals\": [\n",
      "        {\n",
      "            \"name\": \"C&D - Main Entrance\",\n",
      "            \"floor\": 1,\n",
      "            \"keywords\": {\n",
      "                \"X-Coordinate\": 1965,\n",
      "                \"Y-Coordinate\": 1132,\n",
      "                \"Section\": \"C&D\",\n",
      "                \"Keywords\": [\"Coffee and Donuts, Cafe, Coffee Shop, Store, Snacks, Drinks, 1416\"]\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"RoboHub\",\n",
      "            \"floor\": 1,\n",
      "            \"keywords\": {\n",
      "                \"X-Coordinate\": 1339,\n",
      "                \"Y-Coordinate\": 906,\n",
      "                \"Section\": \"RoboHub\",\n",
      "                \"Keywords\": [\"Robotics, 1339, Robot, Drone\"]\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "some_string = '<think>\\nAlright, so I\\'m trying to help the user generate a JSON response for their path planning agent. The prompt they provided is \"Can you pick something up from Zach\\'s office and drop it off at the RoboHub?\" and there\\'s a list of waypoints provided. \\n\\nFirst, I need to understand what each waypoint represents. From the example given, it looks like each location has specific coordinates, keywords, and sections. So, each location\\'s information is tied to these key points.\\n\\nThe user\\'s prompt asks to pick something from Zach\\'s office. So, I should check if Zach\\'s office is listed as a location. Looking at the provided waypoints, the closest is \"C&D - Main Entrance\". But I notice that some locations are more about their features and keywords than just locations. For instance, \"Shower A\" has coordinates but no location name. So, I might need to treat that as a separate entity.\\n\\nSince the user wants to pick something up, I should include the \"C&D - Main Entrance\" as the location to pick from. Then, the target is \"RoboHub\". So, I\\'ll structure the JSON with a \"goals\" array containing two objects: one for picking up from Zach\\'s office and another for dropping it off at RoboHub.\\n\\nI should make sure the keys are correct and match the example provided. That way, the system can interpret the data properly and apply it to the user\\'s query. If I were to write this, I\\'d have to map each location to its respective coordinates and keywords to ensure the system can retrieve the correct information accurately.\\n</think>\\n\\n```json\\n{\\n    \"goals\": [\\n        {\\n            \"name\": \"C&D - Main Entrance\",\\n            \"floor\": 1,\\n            \"keywords\": {\\n                \"X-Coordinate\": 1965,\\n                \"Y-Coordinate\": 1132,\\n                \"Section\": \"C&D\",\\n                \"Keywords\": [\"Coffee and Donuts, Cafe, Coffee Shop, Store, Snacks, Drinks, 1416\"]\\n            }\\n        },\\n        {\\n            \"name\": \"RoboHub\",\\n            \"floor\": 1,\\n            \"keywords\": {\\n                \"X-Coordinate\": 1339,\\n                \"Y-Coordinate\": 906,\\n                \"Section\": \"RoboHub\",\\n                \"Keywords\": [\"Robotics, 1339, Robot, Drone\"]\\n            }\\n        }\\n    ]\\n}\\n```'\n",
    "\n",
    "print(some_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "- Inference latency\n",
    "- RAG / Tool call latency\n",
    "- Model size (if open source)\n",
    "- Model cost (if API like Cohere/OpenAI)\n",
    "- Correctness of outputs:\n",
    "    - LLM Judge → Use a separate LLM to check the output of the one you are experimenting with\n",
    "        - Prompt is not something that is telling the robot do anything dangerous → Sentiment analysis \n",
    "    - Formatting → Is the output in the correct format (i.e. JSON)\n",
    "    - Human Eval → Manually check → possibly build out action path and have human accept or deny\n",
    "    - Validate XRIF itself → make sure XRIF fields are correct → validation script \n",
    "    - Valid waypoints outputted → Doesn’t output a non-existent waypoint \n",
    "    - Checking vector search accuracy → can you partition accurately \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
